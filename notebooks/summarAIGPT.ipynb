{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain openai tiktoken chromadb pypdf sentence_transformers InstructorEmbedding\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6muHcPmZZnr",
        "outputId": "8b1032c2-ad74-44a6-a4d2-e30821609395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.8/479.8 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97_uPV-jXuWd",
        "outputId": "632e79ab-6ca0-4e3f-8805-98c7d2d95844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import trange\n"
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "\n",
        "from InstructorEmbedding import INSTRUCTOR\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import chromadb\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "04hSL4P8aN5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3601dc99-a34b-452f-b9de-a0f6aa335607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Represent the podcast transcript document for retrieval: \"\n",
        "\n",
        "# read transcript data\n",
        "path = '/content/drive/MyDrive/dataset/transcripts-0[0-9].csv'\n",
        "transcripts_df = pd.read_csv(path, index_col=0)\n",
        "\n",
        "\n",
        "\n",
        "# Create list of instruction - transcript pairs (100 first episodes)\n",
        "transcripts_df  = transcripts_df.head(100)\n",
        "texts_with_instructions = []\n",
        "for index, row in transcripts_df.iterrows():\n",
        "    texts_with_instructions.append([instruction, row[\"transcript\"]])\n",
        "\n",
        "# calculate embeddings (100 first episodes took about 6 min)\n",
        "model = INSTRUCTOR('hkunlp/instructor-large')\n",
        "customized_embeddings = model.encode(texts_with_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cUdchN_YC6x",
        "outputId": "69280b9f-1de6-42e1-9db6-9eeeb00a6332"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "persist_directory = '/content/drive/MyDrive/data'\n",
        "\n",
        "# format data that if can be put to the chroma collection\n",
        "embeddings = customized_embeddings.tolist()\n",
        "documents = transcripts_df[\"transcript\"].tolist()\n",
        "ids = transcripts_df.index.astype(str).to_list()\n",
        "metadata = transcripts_df[['episode_description', 'episode_uri']].to_dict(orient='records')\n",
        "\n",
        "#loading into chroma\n",
        "client = chromadb.PersistentClient(path=persist_directory)\n",
        "# create the collection and add documents\n",
        "collection = client.create_collection(\"transcripts\", embedding_function=model)\n",
        "collection.add(\n",
        "    embeddings=embeddings,\n",
        "    documents=documents,\n",
        "    metadatas=metadata,\n",
        "    ids=ids,\n",
        ")"
      ],
      "metadata": {
        "id": "vG0YIWgvYFzW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to load stored embeddings\n",
        "\n",
        "#persist_directory = '/content/drive/MyDrive/database'\n",
        "#client = chromadb.PersistentClient(path=persist_directory)\n",
        "#collection_name = 'transcripts'  # Replace with the name of your collection\n",
        "#collection = client.get_collection(collection_name)"
      ],
      "metadata": {
        "id": "zoY4hI4XaRWP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try querying the database\n",
        "#model = INSTRUCTOR('hkunlp/instructor-large')\n",
        "\n",
        "query_texts=[['Represent the statement for retrieving podcast documents: ',\"I'm looking for podcasts about sports and especially basketball\"]]\n",
        "query_embedding = model.encode(query_texts).tolist()\n",
        "results = collection.query(\n",
        "    query_embeddings=query_embedding,\n",
        "    n_results=1\n",
        ")"
      ],
      "metadata": {
        "id": "ufhXZxEUYJAz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metadatas\n",
        "data = results['metadatas']\n",
        "uri = data[0][0]['episode_uri']\n",
        "print(uri)"
      ],
      "metadata": {
        "id": "ydNsr3Ocg4Ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27da8a3a-c2bb-46bb-c3c8-43b116cbb28f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spotify:episode:6rKQBnTbzCGUfsGfqXxbzD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if results:\n",
        "    # Extract and print the output\n",
        "    output = results['documents'] # Assuming you want the first result\n",
        "    print(\"Query Result:\")\n",
        "    print(output)\n",
        "else:\n",
        "    print(\"No results found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCSxq2J9Ya9A",
        "outputId": "b2a42106-5dcb-47fc-ecfd-398e2bafebb1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Result:\n",
            "[[\"Before we continue. We just want to give a quick shout out to the people who make this podcast possible. Anchor anchor is everything you need to make a podcast in one place. They distribute your podcast for you. They have tools that allow you to record and edit everything right from your phone or computer. It's free the even allow you to put ads in your your podcast. It's pretty awesome. Go check it out download the free anchor app or go to Anchored off dot f m-- to get started. Okay, let's get back to the show. Welcome back to another episode of GRE vocal game. They're gonna do five more words first. We're going to start off by defining each one. Number one acerbic having a sour or bitter taste or character sharp and biting a stringent have I did a tightening effect on living tissue something that tightens your skin pretty much dilettante one with a  an amateurish or superficial interest in the Arts or branch of knowledge kind of like to dabble into something hubris overbearing presumption or Pride arrogance inimical damaging harmful injurious. All right, there's the words. Let's move on to the next section. Alright today, we're talking about the n-b-a. The finals are here case. You didn't know just  We get started. I just wanna let you know I'm a dilettante when it comes to basketball. I like it. I play it. I mean I dabble in it not a master. So I'm going to be hating on anything. I'm about to say here. Yeah, so we got the polemical Warriors who always stir up a controversy and any conversation versus the obdurate unyielding Raptors at the start of the game yesterday the Warriors seemed Halcyon relaxed cool, which is endemic of repeat Champs. They've been  Before you know this isn't phase in them, but the Raptors weren't phase. They got out to a redoubtable lead and but the Warriors new hey, the game was in Kuwait just got started and although they're trailing by 10 and a half. There were still plenty of time. The Raptors had some eclectic scoring coming from many different players and forms. We're talking three pointers pull up. So free throws layups all over and the lead became more and more cogent as time went on you started to be convinced that this was  Going to last often leads against the Warriors are Evanescence. They just kind of vanished and it seems like in a matter of seconds. But the Raptors came to a ver that they are Championship material and honestly, it's hard on him after yesterday Drake the rapper meanwhile with his fund clothes and acerbic comments got the media going many Saw as encores on court presents as kind of a kind of clastic breaking of traditional norms.  For the fans who's walking around talking to the coach. He's kind of like in everyone's face kind of breaching that gap between fans and athletes. He and Draymond Green, they're both Corliss and nature. They both had some words after the game and no one can quite decide whose hubris is larger because they're both pretty arrogant guys also pretty talented, but totally unrelated because I couldn't find how to tie this into basketball. I tried this lotion the other day hoping it would make my skin Moreland.  And smooth but instead it made my skin super tight and uncomfortable. So now I have like these astringent arms and they feel really weird and that lotion is anything but salubrious. I just hope it's not endemic alone. Anyway, it doesn't make me you know, it's not damaging just kind of uncomfortable but time will tell okay. That's all we got for GRE those who can't\"]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB7kWt1Oe0vf",
        "outputId": "bdf93b05-bcc7-4357-c749-c93494eef7e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziBMxVhPe19m",
        "outputId": "43cc7abb-e0ab-4883-d202-adc85a31b9ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Tokenize the text into words\n",
        "    words = nltk.word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    cleaned_text = ' '.join(filtered_words)\n",
        "\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Preprocess the text\n",
        "text = output[0][0]\n",
        "cleaned_text = preprocess_text(text)\n",
        "\n",
        "# Print the cleaned text\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4cHGrotYLaM",
        "outputId": "60175c9d-9ff5-458c-c7c2-6888aa89d30e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before we continue we just want to give a quick shout out to the people who make this podcast possible anchor anchor is everything you need to make a podcast in one place they distribute your podcast for you they have tools that allow you to record and edit everything right from your phone or computer its free the even allow you to put ads in your your podcast its pretty awesome go check it out download the free anchor app or go to anchored off dot f m to get started okay lets get back to the show welcome back to another episode of gre vocal game theyre gonna do five more words first were going to start off by defining each one number one acerbic having a sour or bitter taste or character sharp and biting a stringent have i did a tightening effect on living tissue something that tightens your skin pretty much dilettante one with a an amateurish or superficial interest in the arts or branch of knowledge kind of like to dabble into something hubris overbearing presumption or pride arrogance inimical damaging harmful injurious all right theres the words lets move on to the next section alright today were talking about the nba the finals are here case you didnt know just we get started i just wanna let you know im a dilettante when it comes to basketball i like it i play it i mean i dabble in it not a master so im going to be hating on anything im about to say here yeah so we got the polemical warriors who always stir up a controversy and any conversation versus the obdurate unyielding raptors at the start of the game yesterday the warriors seemed halcyon relaxed cool which is endemic of repeat champs theyve been before you know this isnt phase in them but the raptors werent phase they got out to a redoubtable lead and but the warriors new hey the game was in kuwait just got started and although theyre trailing by and a half there were still plenty of time the raptors had some eclectic scoring coming from many different players and forms were talking three pointers pull up so free throws layups all over and the lead became more and more cogent as time went on you started to be convinced that this was going to last often leads against the warriors are evanescence they just kind of vanished and it seems like in a matter of seconds but the raptors came to a ver that they are championship material and honestly its hard on him after yesterday drake the rapper meanwhile with his fund clothes and acerbic comments got the media going many saw as encores on court presents as kind of a kind of clastic breaking of traditional norms for the fans whos walking around talking to the coach hes kind of like in everyones face kind of breaching that gap between fans and athletes he and draymond green theyre both corliss and nature they both had some words after the game and no one can quite decide whose hubris is larger because theyre both pretty arrogant guys also pretty talented but totally unrelated because i couldnt find how to tie this into basketball i tried this lotion the other day hoping it would make my skin moreland and smooth but instead it made my skin super tight and uncomfortable so now i have like these astringent arms and they feel really weird and that lotion is anything but salubrious i just hope its not endemic alone anyway it doesnt make me you know its not damaging just kind of uncomfortable but time will tell okay thats all we got for gre those who cant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# Set up your OpenAI API key\n",
        "\n",
        "\n",
        "api_key = \"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\"\n",
        "openai.api_key = api_key\n",
        "\n",
        "user_message_content = f\"{cleaned_text} {uri}\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with transcript of podcast show, and your task is to summarize the transcript as follows:\\n\\n-elaborate summary of transcript\\n-Name of the show\\n-episode_uri\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": user_message_content\n",
        "    }\n",
        "  ],\n",
        "  temperature=0, # Controls the randomness of the response\n",
        "  max_tokens=2500,\n",
        "  top_p=1, #It controls the diversity and randomness of the generated text\n",
        "  frequency_penalty=0, # Adjusts the likelihood of words appearing frequently\n",
        "  presence_penalty=0. # Adjusts the likelihood of model-generated content being present\n",
        ")"
      ],
      "metadata": {
        "id": "SS6394Bzl--T"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_response = response['choices'][0]['message']['content']\n",
        "print(output_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJyXqqV6r7D5",
        "outputId": "0054e872-db61-4dd9-e36f-a6f63a1f4d3b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Show: GRE Vocal Game\n",
            "Episode URI: spotify:episode:6rKQBnTbzCGUfsGfqXxbzD\n",
            "\n",
            "Summary:\n",
            "In this episode of GRE Vocal Game, the host starts by defining five words: acerbic, astringent, dilettante, hubris, and inimical. Then, the host moves on to discuss the NBA finals, admitting to being a dilettante when it comes to basketball. The host describes the Golden State Warriors as polemical and the Toronto Raptors as obdurate. The game starts with the Warriors appearing relaxed, but the Raptors take an early lead. The Raptors' diverse scoring methods make their lead more convincing. The host mentions Drake's acerbic comments and unconventional behavior during the game. The host also mentions the post-game exchange between Drake and Draymond Green, both known for their arrogance. The host briefly mentions trying a lotion that had an astringent effect on their skin. The episode concludes with the hope that the lotion is not damaging in the long run.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"summary1.txt\", \"w\") as f:\n",
        "    f.write(\"\".join(output_response))"
      ],
      "metadata": {
        "id": "Ca1hAWMawK4Z"
      },
      "execution_count": 49,
      "outputs": []
    }
  ]
}